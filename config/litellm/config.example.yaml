# LiteLLM Proxy Configuration Example
# Full documentation: https://docs.litellm.ai/docs/proxy/config_settings

model_list:  # List of model deployments https://docs.litellm.ai/docs/proxy/configs#model-list

  - model_name: gemini-claude-sonnet-4-5
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: tab_flash_lite_preview
    litellm_params:
      model: google/tab-flash-lite
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-claude-sonnet-4-5-thinking
    litellm_params:
      model: anthropic/claude-sonnet-4-5-thinking
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-2.5-computer-use-preview-10-2025
    litellm_params:
      model: google/rev19-uic3-1p
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-claude-opus-4-5-thinking
    litellm_params:
      model: anthropic/claude-opus-4-5-thinking
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-3-flash-preview
    litellm_params:
      model: google/gemini-3-flash
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-2.5-pro
    litellm_params:
      model: google/gemini-2.5-pro
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gpt-oss-120b-medium
    litellm_params:
      model: google/gpt-oss-120b
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-3-pro-image-preview
    litellm_params:
      model: google/gemini-3-pro-image
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-3-pro-preview
    litellm_params:
      model: google/gemini-3-pro-high
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: google/gemini-2.5-flash-lite
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

  - model_name: gemini-2.5-flash
    litellm_params:
      model: google/gemini-2.5-flash
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY

# Global settings for all LLM calls https://docs.litellm.ai/docs/proxy/config_settings#litellm_settings---reference
litellm_settings:
  drop_params: True  # Drop unsupported params instead of failing https://docs.litellm.ai/docs/proxy/config_settings#drop_params
  success_callback: ["langfuse", "prometheus"]  # Callbacks on successful requests https://docs.litellm.ai/docs/proxy/logging
  failure_callback: ["prometheus", "langfuse"]  # Callbacks on failed requests
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST
  check_provider_endpoint: true  # Validate provider endpoint before calls https://docs.litellm.ai/docs/proxy/config_settings
  turn_off_message_logging: False  # Log metadata only, not full messages https://docs.litellm.ai/docs/proxy/config_settings#turn_off_message_logging
  redact_user_api_key_info: true  # Hide sensitive key info in logs https://docs.litellm.ai/docs/proxy/config_settings#redact_user_api_key_info
  cache: False  # Enable/disable response caching https://docs.litellm.ai/docs/proxy/caching
  enable_caching_on_provider_specific_optional_params: True  # Cache provider-specific params https://docs.litellm.ai/docs/proxy/caching
  cache_params:  # Cache configuration https://docs.litellm.ai/docs/proxy/caching#supported-cache_params-on-proxy-configyaml
    type: redis  # Cache type: local, redis, s3, gcs https://docs.litellm.ai/docs/proxy/caching
    host: os.environ/REDIS_HOST  # Redis host from env var
    port: os.environ/REDIS_PORT  # Redis port from env var
    password: os.environ/REDIS_PASSWORD  # Redis password from env var
    ttl: 3600  # Default cache TTL in seconds (1 hour)

# Router configuration for load balancing and failover https://docs.litellm.ai/docs/proxy/config_settings#router_settings---reference
router_settings:
  routing_strategy: simple-shuffle # Literal["simple-shuffle", "least-busy", "usage-based-routing","latency-based-routing"], default="simple-shuffle" - RECOMMENDED for best performance
  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  redis_password: os.environ/REDIS_PASSWORD
  enable_pre_call_checks: true  # Check context window before calls https://docs.litellm.ai/docs/proxy/reliability
  allowed_fails: 3  # Max failures before cooldown https://docs.litellm.ai/docs/proxy/config_settings#allowed_fails
  cooldown_time: 30  # Cooldown duration in seconds https://docs.litellm.ai/docs/proxy/config_settings#cooldown_time
  timeout: 300  # Default request timeout in seconds https://docs.litellm.ai/docs/proxy/config_settings#timeout
  stream_timeout: 180  # Streaming request timeout in seconds https://docs.litellm.ai/docs/proxy/config_settings#stream_timeout

# General proxy configuration https://docs.litellm.ai/docs/proxy/config_settings#general_settings---reference
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY  # Required for UI and Virtual Keys
  database_url: os.environ/DATABASE_URL  # Required for Virtual Keys
  ui_access_mode: admin_only  # Enable Admin UI for admins
  alerting: ["slack"]  # Alert channels for failures/errors https://docs.litellm.ai/docs/proxy/alerting
  store_model_in_db: true  # Persist model config in database https://docs.litellm.ai/docs/proxy/config_settings#store_model_in_db
  store_prompts_in_spend_logs: true  # Save prompts/responses in spend logs https://docs.litellm.ai/docs/proxy/config_settings#store_prompts_in_spend_logs
  maximum_spend_logs_retention_period: 3d  # Retain logs for 3 days only
  maximum_spend_logs_retention_interval: 1h  # Run cleanup task every hour
