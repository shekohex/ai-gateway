# LiteLLM Proxy Configuration Example
# Full documentation: https://docs.litellm.ai/docs/proxy/config_settings

# Global settings for all LLM calls https://docs.litellm.ai/docs/proxy/config_settings#litellm_settings---reference
litellm_settings:
  drop_params: True # Drop unsupported params instead of failing https://docs.litellm.ai/docs/proxy/config_settings#drop_params
  success_callback: [] # Callbacks on successful requests https://docs.litellm.ai/docs/proxy/logging
  failure_callback: [] # Callbacks on failed requests
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST
  check_provider_endpoint: true # Validate provider endpoint before calls https://docs.litellm.ai/docs/proxy/config_settings
  turn_off_message_logging: False # Log metadata only, not full messages https://docs.litellm.ai/docs/proxy/config_settings#turn_off_message_logging
  redact_user_api_key_info: true # Hide sensitive key info in logs https://docs.litellm.ai/docs/proxy/config_settings#redact_user_api_key_info
  set_verbose: False
  request_timeout: 1200
  json_logs: False # Get debug logs in json format
  cache: False # Enable/disable response caching https://docs.litellm.ai/docs/proxy/caching
  enable_caching_on_provider_specific_optional_params: True # Cache provider-specific params https://docs.litellm.ai/docs/proxy/caching
  cache_params: # Cache configuration https://docs.litellm.ai/docs/proxy/caching#supported-cache_params-on-proxy-configyaml
    type: redis # Cache type: local, redis, s3, gcs https://docs.litellm.ai/docs/proxy/caching
    host: os.environ/REDIS_HOST # Redis host from env var
    port: os.environ/REDIS_PORT # Redis port from env var
    password: os.environ/REDIS_PASSWORD # Redis password from env var
    ttl: 3600 # Default cache TTL in seconds (1 hour)

# Router configuration for load balancing and failover https://docs.litellm.ai/docs/proxy/config_settings#router_settings---reference
router_settings:
  routing_strategy: simple-shuffle # Literal["simple-shuffle", "least-busy", "usage-based-routing","latency-based-routing"], default="simple-shuffle" - RECOMMENDED for best performance
  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  redis_password: os.environ/REDIS_PASSWORD
  enable_pre_call_checks: true # Required for 'order' parameter to work https://docs.litellm.ai/docs/proxy/load_balancing#deployment-ordering-priority
  allowed_fails: 3 # Max failures before cooldown https://docs.litellm.ai/docs/proxy/config_settings#allowed_fails
  cooldown_time: 30 # Cooldown duration in seconds https://docs.litellm.ai/docs/proxy/config_settings#cooldown_time
  timeout: 300 # Default request timeout in seconds https://docs.litellm.ai/docs/proxy/config_settings#timeout
  stream_timeout: 300 # Streaming request timeout in seconds https://docs.litellm.ai/docs/proxy/config_settings#stream_timeout

# General proxy configuration https://docs.litellm.ai/docs/proxy/config_settings#general_settings---reference
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY # Required for UI and Virtual Keys
  database_url: os.environ/DATABASE_URL # Required for Virtual Keys
  ui_access_mode: admin_only # Enable Admin UI for admins
  alerting: [] # Alert channels for failures/errors https://docs.litellm.ai/docs/proxy/alerting
  store_model_in_db: true # Persist model config in database https://docs.litellm.ai/docs/proxy/config_settings#store_model_in_db
  block_robots: true
  proxy_batch_write_at: 60
  disable_error_logs: True
  store_prompts_in_spend_logs: true # Save prompts/responses in spend logs https://docs.litellm.ai/docs/proxy/config_settings#store_prompts_in_spend_logs
  maximum_spend_logs_retention_period: 3d # Retain logs for 3 days only
  maximum_spend_logs_retention_interval: 1h # Run cleanup task every hour

router:
  # Search tools that AI can invoke and use.
  # https://docs.litellm.ai/docs/search/
  search_tools:
    - search_tool_name: firecrawl-search
      litellm_params:
        search_provider: firecrawl
        api_base: os.environ/FIRECRAWL_API_BASE
        api_key: os.environ/FIRECRAWL_API_KEY

# Centralized Credential Management
# Define credentials once and reuse across models for easier secret rotation
credential_list:
  - credential_name: cliproxyapi_credential
    credential_values:
      api_base: os.environ/CLIPROXYAPI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY
    credential_info:
      description: "CLIProxyAPI credentials (Base)"

  - credential_name: cliproxyapi_credential_openai
    credential_values:
      api_base: os.environ/CLIPROXYAPI_OPENAI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY
    credential_info:
      description: "CLIProxyAPI credentials (OpenAI-compatible)"

  - credential_name: cliproxyapi_credential_gemini
    credential_values:
      api_base: os.environ/CLIPROXYAPI_GEMINI_BASE_URL
      api_key: os.environ/CLIPROXYAPI_KEY
    credential_info:
      description: "CLIProxyAPI credentials (Gemini-compatible)"

  - credential_name: zai_coding_credential
    credential_values:
      api_base: https://api.z.ai/api/coding/paas/v4
      api_key: os.environ/ZAI_API_KEY
    credential_info:
      description: "Z.AI Coding Plan credentials (OpenAI-compatible)"

  - credential_name: zai_anthropic_credential
    credential_values:
      api_base: https://api.z.ai/api/anthropic
      api_key: os.environ/ZAI_API_KEY
    credential_info:
      description: "Z.AI Anthropic Format credentials"

  - credential_name: kimi_coding_credential
    credential_values:
      api_base: https://api.kimi.com/coding/v1
      api_key: os.environ/KIMI_API_KEY
    credential_info:
      description: "Kimi Coding Plan credentials (OpenAI-compatible)"

  - credential_name: speaches_credential
    credential_values:
      api_base: os.environ/SPEACHES_API_BASE
      api_key: os.environ/SPEACHES_API_KEY
    credential_info:
      description: "Speaches.ai credentials (OpenAI-compatible STT/TTS)"

  - credential_name: egyptalk_credential
    credential_values:
      api_base: os.environ/EGYPTALK_ASR_BASE
      api_key: os.environ/EGYPTALK_ASR_API
    credential_info:
      description: "EgypTalk ASR credentials"

  - credential_name: gigabrain_credential
    credential_values:
      api_base: os.environ/GIGABRAIN_BASE_URL
      api_key: os.environ/GIGABRAIN_API_KEY
    credential_info:
      description: "Gigabrain credentials"

  - credential_name: opencode_zen_openai_credential
    credential_values:
      api_base: https://opencode.ai/zen/v1
      api_key: os.environ/OPENCODE_ZEN_API_KEY
    credential_info:
      description: "OpenCode Zen credentials (OpenAI-compatible)"

  - credential_name: opencode_zen_anthropic_credential
    credential_values:
      api_base: https://opencode.ai/zen
      api_key: os.environ/OPENCODE_ZEN_API_KEY
    credential_info:
      description: "OpenCode Zen credentials (Anthropic-compatible)"

  - credential_name: opencode_zen_gemini_credential
    credential_values:
      api_base: https://opencode.ai/zen/v1
      api_key: os.environ/OPENCODE_ZEN_API_KEY
    credential_info:
      description: "OpenCode Zen credentials (Gemini-compatible)"

  - credential_name: google_gemini_credential
    credential_values:
      api_base: https://generativelanguage.googleapis.com
      api_key: os.environ/GEMINI_API_KEY
    credential_info:
      description: "Google Gemini credentials"
  - credential_name: openai_credential
    credential_values:
      api_base: https://api.openai.com/v1
      api_key: os.environ/OPENAI_API_KEY
    credential_info:
      description: "OpenAI credentials"

model_list:
  # --------------------------------------------------
  # OpenAI Models (CLIProxyAPI)
  # --------------------------------------------------
  - model_name: gpt-5
    litellm_params:
      model: openai/gpt-5
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5
#     litellm_params:
#       model: openai/gpt-5
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5-chat-latest
    litellm_params:
      model: openai/gpt-5
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5-chat-latest
#     litellm_params:
#       model: openai/gpt-5
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5-codex
    litellm_params:
      model: openai/gpt-5-codex
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5-codex
#     litellm_params:
#       model: openai/gpt-5-codex
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5-codex-mini
    litellm_params:
      model: openai/gpt-5-codex-mini
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

  - model_name: gpt-5.2
    litellm_params:
      model: openai/gpt-5.2
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5.2
#     litellm_params:
#       model: openai/gpt-5.2
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5.2-chat-latest
    litellm_params:
      model: openai/gpt-5.2
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5.2-chat-latest
#     litellm_params:
#       model: openai/gpt-5.2
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5.2-codex
    litellm_params:
      model: openai/gpt-5.2-codex
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5.2-codex
#     litellm_params:
#       model: openai/gpt-5.2-codex
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5.1-codex
    litellm_params:
      model: openai/gpt-5.1-codex
      litellm_credential_name: opencode_zen_openai_credential
      order: 1

  - model_name: gpt-5.1-codex
    litellm_params:
      model: openai/gpt-5-codex
      litellm_credential_name: cliproxyapi_credential_openai
      order: 2

  - model_name: gpt-5.1
    litellm_params:
      model: openai/gpt-5.1
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5.1
#     litellm_params:
#       model: openai/gpt-5.1
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5.1-chat-latest
    litellm_params:
      model: openai/gpt-5.1
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5.1-chat-latest
#     litellm_params:
#       model: openai/gpt-5.1
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5.1-codex-max
    litellm_params:
      model: openai/gpt-5.1-codex-max
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5.1-codex-max
#     litellm_params:
#       model: openai/gpt-5.1-codex-max
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5.1-codex-mini
    litellm_params:
      model: openai/gpt-5.1-codex-mini
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

#   - model_name: gpt-5.1-codex-mini
#     litellm_params:
#       model: openai/gpt-5.1-codex-mini
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: gpt-5-mini
    litellm_params:
      model: openai/gpt-5-codex-mini
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

  - model_name: gpt-5-nano
    litellm_params:
      model: openai/gpt-5-nano
      litellm_credential_name: opencode_zen_openai_credential
      order: 1

  - model_name: gpt-5-nano
    litellm_params:
      model: openai/gpt-5.1-codex-mini
      litellm_credential_name: cliproxyapi_credential_openai
      order: 2

  - model_name: gpt-5-pro
    litellm_params:
      model: openai/gpt-5
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

  - model_name: gpt-5.2-pro
    litellm_params:
      model: openai/gpt-5.2
      litellm_credential_name: cliproxyapi_credential_openai
      order: 1

  # --------------------------------------------------
  # Antigravity models (CLIProxyAPI) - Priority order: 1
  # --------------------------------------------------
  - model_name: claude-sonnet-4-5
    litellm_params:
      model: anthropic/claude-sonnet-4-5-thinking
      litellm_credential_name: cliproxyapi_credential
      order: 1

#   - model_name: claude-sonnet-4-5
#     litellm_params:
#       model: anthropic/claude-sonnet-4-5
#       litellm_credential_name: opencode_zen_anthropic_credential
#       order: 2
# 
  - model_name: claude-opus-4-5
    litellm_params:
      model: anthropic/claude-opus-4-5-thinking
      litellm_credential_name: cliproxyapi_credential
      order: 1

#   - model_name: claude-opus-4-5
#     litellm_params:
#       model: anthropic/claude-opus-4-5
#       litellm_credential_name: opencode_zen_anthropic_credential
#       order: 2
# 
  - model_name: claude-sonnet-4-5-20250929
    litellm_params:
      model: anthropic/claude-sonnet-4-5-thinking
      litellm_credential_name: cliproxyapi_credential
      order: 1

  - model_name: claude-opus-4-5-20251101
    litellm_params:
      model: anthropic/claude-opus-4-5-thinking
      litellm_credential_name: cliproxyapi_credential
      order: 1

  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4
      litellm_credential_name: opencode_zen_anthropic_credential
      order: 1

  - model_name: claude-haiku-4-5
    litellm_params:
      model: anthropic/claude-haiku-4-5
      litellm_credential_name: opencode_zen_anthropic_credential
      order: 1

  - model_name: claude-3-5-haiku
    litellm_params:
      model: anthropic/claude-3-5-haiku
      litellm_credential_name: opencode_zen_anthropic_credential
      order: 1

  - model_name: claude-opus-4-1
    litellm_params:
      model: anthropic/claude-opus-4-1
      litellm_credential_name: opencode_zen_anthropic_credential
      order: 1

  - model_name: gemini-3-flash-preview
    litellm_params:
      model: gemini/gemini-3-flash-preview
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1
    model_info:
      supports_web_search: True

  - model_name: gemini-3-pro-preview
    litellm_params:
      model: gemini/gemini-3-pro-preview
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-3-flash
    litellm_params:
      model: gemini/gemini-3-flash
      litellm_credential_name: opencode_zen_gemini_credential
      order: 1

  - model_name: gemini-3-pro
    litellm_params:
      model: gemini/gemini-3-pro
      litellm_credential_name: opencode_zen_gemini_credential
      order: 1

  - model_name: gemini-3-pro-image-preview
    litellm_params:
      model: gemini/gemini-3-pro-image-preview
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1
    model_info:
      supports_web_search: True

  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1
    model_info:
      supports_web_search: True

  # --------------------------------------------------
  # Google/Gemini-CLI models (CLIProxyAPI) - Fallback order: 2
  # --------------------------------------------------
  # Overlapping models - Gemini-CLI fallback (order: 2)
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/google-gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2
    model_info:
      supports_web_search: True

  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: gemini/google-gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2
    model_info:
      supports_web_search: True

  - model_name: gemini-3-flash-preview
    litellm_params:
      model: gemini/google-gemini-3-flash-preview
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  - model_name: gemini-3-pro-preview
    litellm_params:
      model: gemini/google-gemini-3-pro-preview
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  # --------------------------------------------------
  # Gemini 2.5 Preview Aliases - Compatibility for dated versions
  # --------------------------------------------------
  - model_name: gemini-2.5-flash-preview-04-17
    litellm_params:
      model: gemini/gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-flash-preview-04-17
    litellm_params:
      model: gemini/google-gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  - model_name: gemini-2.5-flash-preview-05-20
    litellm_params:
      model: gemini/gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-flash-preview-05-20
    litellm_params:
      model: gemini/google-gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  - model_name: gemini-2.5-flash-preview-09-2025
    litellm_params:
      model: gemini/gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-flash-preview-09-2025
    litellm_params:
      model: gemini/google-gemini-2.5-flash
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  - model_name: gemini-2.5-flash-lite-preview-06-17
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-flash-lite-preview-06-17
    litellm_params:
      model: gemini/google-gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  - model_name: gemini-2.5-flash-lite-preview-09-2025
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-flash-lite-preview-09-2025
    litellm_params:
      model: gemini/google-gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  - model_name: gemini-2.5-pro-preview-05-06
    litellm_params:
      model: gemini/gemini-2.5-pro
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-2.5-pro-preview-06-05
    litellm_params:
      model: gemini/gemini-2.5-pro
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  # --------------------------------------------------
  # Gemini Latest Aliases - Point to 3.0 preview models
  # --------------------------------------------------
  - model_name: gemini-flash-latest
    litellm_params:
      model: gemini/gemini-3-flash-preview
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-flash-latest
    litellm_params:
      model: gemini/google-gemini-3-flash-preview
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  - model_name: gemini-flash-lite-latest
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 1

  - model_name: gemini-flash-lite-latest
    litellm_params:
      model: gemini/google-gemini-2.5-flash-lite
      litellm_credential_name: cliproxyapi_credential_gemini
      order: 2

  # --------------------------------------------------
  # Audio Models (Speaches & EgypTalk, Gemini)
  # --------------------------------------------------
  # TTS
  - model_name: tts-kokoro
    litellm_params:
      model: openai/speaches-ai/Kokoro-82M-v1.0-ONNX-fp16
      litellm_credential_name: speaches_credential
    model_info:
      mode: audio_speech
      supports_audio_output: True
      supports_audio_input: True
      input_cost_per_character: 0.000015

  - model_name: tts-1
    litellm_params:
      model: openai/speaches-ai/Kokoro-82M-v1.0-ONNX-fp16
      litellm_credential_name: speaches_credential
    model_info:
      mode: audio_speech
      supports_audio_output: True
      supports_audio_input: True
      input_cost_per_character: 0.000015

  - model_name: tts-1-hd
    litellm_params:
      model: openai/speaches-ai/Kokoro-82M-v1.0-ONNX-fp16
      litellm_credential_name: speaches_credential
    model_info:
      mode: audio_speech
      supports_audio_output: True
      supports_audio_input: True
      input_cost_per_character: 0.00003

  - model_name: gemini-2.5-flash-preview-tts
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-tts
      litellm_credential_name: google_gemini_credential
    model_info:
      mode: audio_speech
      supports_audio_output: True
      supports_audio_input: True

  - model_name: gemini-2.5-pro-preview-tts
    litellm_params:
      model: gemini/gemini-2.5-pro-preview-tts
      litellm_credential_name: google_gemini_credential
    model_info:
      mode: audio_speech
      supports_audio_output: True
      supports_audio_input: True

  - model_name: gpt-4o-mini-tts
    litellm_params:
      model: openai/gpt-4o-mini-tts
      litellm_credential_name: openai_credential
    model_info:
      mode: audio_speech
      supports_audio_output: True
      supports_audio_input: False

  # STT (Transcription)
  - model_name: whisper-1
    litellm_params:
      model: openai/Systran/faster-whisper-large-v3
      litellm_credential_name: speaches_credential
    model_info:
      mode: audio_transcription
      input_cost_per_second: 0.00003083

  - model_name: whisper-large-v3
    litellm_params:
      model: openai/Systran/faster-whisper-large-v3
      litellm_credential_name: speaches_credential
    model_info:
      mode: audio_transcription
      input_cost_per_second: 0.00003083

  - model_name: whisper-distil-large-v3.5
    litellm_params:
      model: openai/distil-whisper/distil-large-v3.5-ct2
      litellm_credential_name: speaches_credential
    model_info:
      mode: audio_transcription
      input_cost_per_second: 0.00001111

  - model_name: whisper-turbo
    litellm_params:
      model: openai/deepdml/faster-whisper-large-v3-turbo-ct2
      litellm_credential_name: speaches_credential
    model_info:
      mode: audio_transcription
      input_cost_per_second: 0.00000556

  - model_name: egyptalk-asr
    litellm_params:
      model: openai/egyptalk-asr-v2
      litellm_credential_name: egyptalk_credential
    model_info:
      mode: audio_transcription
      input_cost_per_second: 0.00003083

  - model_name: glm-asr-2512
    litellm_params:
      model: zai/glm-asr-2512
      litellm_credential_name: zai_coding_credential
      input_cost_per_token: 3e-8
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: audio_transcription

  - model_name: glm-asr-latest
    litellm_params:
      model: zai/glm-asr-2512
      litellm_credential_name: zai_coding_credential
      input_cost_per_token: 3e-8
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: audio_transcription

  - model_name: gpt-4o-transcribe
    litellm_params:
      model: openai/gpt-4o-transcribe
      litellm_credential_name: openai_credential
    model_info:
      mode: audio_transcription
      supports_audio_output: False
      supports_audio_input: True

  - model_name: gpt-4o-mini-transcribe
    litellm_params:
      model: openai/gpt-4o-mini-transcribe
      litellm_credential_name: openai_credential
    model_info:
      mode: audio_transcription
      supports_audio_output: False
      supports_audio_input: True
  # --------------------------------------------------
  # Image Generation Models (Z.AI)
  # --------------------------------------------------
  - model_name: glm-image
    litellm_params:
      model: zai/glm-image
      litellm_credential_name: zai_coding_credential
      output_cost_per_image: 0.015
      input_cost_per_image: 0.015
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: image_generation

  # --------------------------------------------------
  # Z.AI Anthropic Format - Anthropic-compatible Endpoint (same GLM models)
  # --------------------------------------------------
  - model_name: glm-4.7
    litellm_params:
      model: anthropic/glm-4.7
      litellm_credential_name: zai_anthropic_credential
      order: 1
      max_input_tokens: 200000
      max_output_tokens: 128000
      input_cost_per_token: 6e-7
      output_cost_per_token: 0.0000022
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 200000
      max_input_tokens: 200000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

#   - model_name: glm-4.7
#     litellm_params:
#       model: openai/glm-4.7
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: glm-4.7-flashx
    litellm_params:
      model: anthropic/glm-4.7-flashx
      litellm_credential_name: zai_anthropic_credential
      max_input_tokens: 200000
      max_output_tokens: 128000
      input_cost_per_token: 7e-8
      output_cost_per_token: 4e-7
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 200000
      max_input_tokens: 200000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

  - model_name: glm-4.6
    litellm_params:
      model: anthropic/glm-4.6
      litellm_credential_name: zai_anthropic_credential
      order: 1
      max_input_tokens: 200000
      max_output_tokens: 128000
      input_cost_per_token: 6e-7
      output_cost_per_token: 0.0000022
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 200000
      max_input_tokens: 200000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

#   - model_name: glm-4.6
#     litellm_params:
#       model: openai/glm-4.6
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: glm-4.6v
    litellm_params:
      model: anthropic/glm-4.6v
      litellm_credential_name: zai_anthropic_credential
      max_input_tokens: 128000
      max_output_tokens: 128000
      input_cost_per_token: 3e-7
      output_cost_per_token: 9e-7
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 128000
      max_input_tokens: 128000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: true
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

  - model_name: glm-4.5
    litellm_params:
      model: anthropic/glm-4.5
      litellm_credential_name: zai_anthropic_credential
      max_input_tokens: 128000
      max_output_tokens: 128000
      input_cost_per_token: 6e-7
      output_cost_per_token: 0.0000022
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 128000
      max_input_tokens: 128000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

  - model_name: glm-4.5-flash
    litellm_params:
      model: anthropic/glm-4.5-flash
      litellm_credential_name: zai_anthropic_credential
      max_input_tokens: 128000
      max_output_tokens: 128000
      input_cost_per_token: 0
      output_cost_per_token: 0
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 128000
      max_input_tokens: 128000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

  - model_name: glm-4.5-air
    litellm_params:
      model: anthropic/glm-4.5-air
      litellm_credential_name: zai_anthropic_credential
      max_input_tokens: 128000
      max_output_tokens: 128000
      input_cost_per_token: 2e-7
      output_cost_per_token: 0.0000011
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 128000
      max_input_tokens: 128000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

  - model_name: glm-4.5-airx
    litellm_params:
      model: anthropic/glm-4.5-airx
      litellm_credential_name: zai_anthropic_credential
      max_input_tokens: 128000
      max_output_tokens: 128000
      input_cost_per_token: 0.0000011
      output_cost_per_token: 0.0000045
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://docs.z.ai/guides/overview/pricing"
    model_info:
      mode: chat
      max_tokens: 128000
      max_input_tokens: 128000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

  - model_name: kimi/k2p5
    litellm_params:
      model: openai/k2p5
      use_in_pass_through: true
      litellm_credential_name: kimi_coding_credential
      api_key: os.environ/KIMI_API_KEY
      max_input_tokens: 262144
      max_output_tokens: 32768
      input_cost_per_token: 6e-7
      output_cost_per_token: 0.000003
      cache_read_input_token_cost: 1e-7
      supports_function_calling: true
      supports_tool_choice: true
      source: "https://www.kimi.com/coding/docs/en/third-party-agents.html"
    model_info:
      mode: chat
      max_tokens: 262144
      max_input_tokens: 262144
      max_output_tokens: 32768
      supports_system_messages: true
      supports_prompt_caching: false
      supports_vision: true
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: true
      supports_function_calling: true
      supports_response_schema: true

  # --------------------------------------------------
  # Gigabrain Models (Bigboss)
  # --------------------------------------------------
  - model_name: gemma3
    litellm_params:
      model: openai/gemma3
      litellm_credential_name: gigabrain_credential
      max_input_tokens: 32000
      max_output_tokens: 32000
      input_cost_per_token: 0
      output_cost_per_token: 0
      supports_function_calling: true
      supports_tool_choice: true
    model_info:
      mode: chat
      max_tokens: 32000
      max_input_tokens: 32000
      max_output_tokens: 32000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: true
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: false
      supports_function_calling: true
      supports_response_schema: true

  - model_name: qwen3
    litellm_params:
      model: openai/qwen3
      litellm_credential_name: gigabrain_credential
      max_input_tokens: 128000
      max_output_tokens: 128000
      input_cost_per_token: 0
      output_cost_per_token: 0
      supports_function_calling: true
      supports_tool_choice: true
    model_info:
      mode: chat
      max_tokens: 128000
      max_input_tokens: 128000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: false
      supports_function_calling: true
      supports_response_schema: true

  - model_name: qwen3-coder
    litellm_params:
      model: openai/qwen3-coder
      litellm_credential_name: gigabrain_credential
      order: 1
      max_input_tokens: 128000
      max_output_tokens: 128000
      input_cost_per_token: 0
      output_cost_per_token: 0
      supports_function_calling: true
      supports_tool_choice: true
    model_info:
      mode: chat
      max_tokens: 128000
      max_input_tokens: 128000
      max_output_tokens: 128000
      supports_system_messages: true
      supports_prompt_caching: true
      supports_vision: false
      supports_audio_input: false
      supports_web_search: false
      supports_reasoning: false
      supports_function_calling: true
      supports_response_schema: true

#   - model_name: qwen3-coder
#     litellm_params:
#       model: openai/qwen3-coder
#       litellm_credential_name: opencode_zen_openai_credential
#       order: 2
# 
  - model_name: kimi-k2
    litellm_params:
      model: openai/kimi-k2
      litellm_credential_name: opencode_zen_openai_credential
      order: 1

  - model_name: kimi-k2-thinking
    litellm_params:
      model: openai/kimi-k2-thinking
      litellm_credential_name: opencode_zen_openai_credential
      order: 1

  - model_name: grok-code
    litellm_params:
      model: openai/grok-code
      litellm_credential_name: opencode_zen_openai_credential
      order: 1

  - model_name: big-pickle
    litellm_params:
      model: openai/big-pickle
      litellm_credential_name: opencode_zen_openai_credential
      order: 1

  - model_name: qwen3-embedding
    litellm_params:
      model: openai/qwen3-embedding
      litellm_credential_name: gigabrain_credential

  - model_name: text-embedding-3-large
    litellm_params:
      model: openai/qwen3-embedding
      litellm_credential_name: gigabrain_credential
